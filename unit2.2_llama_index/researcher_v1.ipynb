{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/maksim.rostov/pdev/freestyling/agents/hf-course/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "emb_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.llms.ollama import Ollama  \n",
        "\n",
        "chat_model = Ollama(model=\"qwen2:7b\", context_window=89000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnsDEuS1wHh-"
      },
      "source": [
        "## Researcher: An Agent Workflow\n",
        "\n",
        "Let's create an agent workflow that would: \n",
        " 1) Take a topic to write a blogpost about and subdivide it into sections\n",
        " 2) The first section should include variables, definitions, concepts and terminology that are going to be used for explaining (mathematicaly) the problem   \n",
        "    - Briefly explain those concepts \n",
        " 3) Look up websites that explain the topic  \n",
        "    - Download the selected websites and process their data (make a note that you need to refence them)\n",
        "    - Select websites that best fit the subsections identified before  \n",
        "    - Decide which website is the best at explaining the topic based on how it covers the subsections\n",
        "1) Analyse the website and change rearrange its content to fit the desired subsection structure and the variables and defintions  \n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/07/24 19:01:53 INFO mlflow.tracking.fluent: Experiment with name '2025-07-24T19:01:53.344213' does not exist. Creating a new experiment.\n"
          ]
        }
      ],
      "source": [
        "import urllib.error\n",
        "import urllib.error\n",
        "import urllib.request\n",
        "\n",
        "from llama_index.core.workflow import (\n",
        "    InputRequiredEvent,\n",
        "    HumanResponseEvent,\n",
        ")\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.workflow import Context\n",
        "import mlflow\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "mlflow.set_experiment(experiment_name=datetime.now().isoformat())\n",
        "mlflow.set_tracking_uri('http://localhost:5000')\n",
        "mlflow.llama_index.autolog()\n",
        "\n",
        "\n",
        "def get_relevant_webpages(ctx: Context, query: str) -> tuple[list[dict[str, str]], int]:\n",
        "    \"\"\"\n",
        "    Gets the url of the most relevant webpages for the query.\n",
        "\n",
        "    Args:\n",
        "        query (str): what to search online on www.\n",
        "\n",
        "    Returns:\n",
        "        str: url link.\n",
        "    \"\"\"\n",
        "    from ddgs import DDGS\n",
        "\n",
        "    search_ggg = DDGS()\n",
        "    results = search_ggg.text(query=query, max_results=1)\n",
        "    return results[0][\"href\"]\n",
        "\n",
        "def download_webpage(ctx: Context, url: str) -> str:\n",
        "    \"\"\"\n",
        "    Load the raw webpage of the url. Store it in the context.\n",
        "    \n",
        "    Args:\n",
        "        url (str): www url of the page.\n",
        "    \n",
        "    Returns: \n",
        "        str: html string of the whole webpage.\n",
        "    \"\"\"\n",
        "    try: \n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            html_text = response.read()\n",
        "            ctx.store.set(\"html_resource\", html_text)\n",
        "            print(html_text)\n",
        "            return html_text\n",
        "    except urllib.error.URLError as e:\n",
        "        print(\"Error getting the page.\")\n",
        "    except Exception as e:\n",
        "        print(\"Something happened.\")\n",
        "\n",
        "def generate_blogpost(ctx: Context, text: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate a blogpost in a markdown format based on the raw of a resource. \n",
        "    \"\"\"\n",
        "    task = f\"Based on the this resource html {text}, generate a blogpost about the topic in markdown format.\"\n",
        "    resp = chat_model.complete(task)\n",
        "\n",
        "    print(resp.text)\n",
        "\n",
        "    while True: \n",
        "        question = \"do you like what you see?\"\n",
        "        human_feedback = ctx.wait_for_event(\n",
        "            HumanResponseEvent,\n",
        "            waiter_id=question,\n",
        "            waiter_event=InputRequiredEvent(\n",
        "                prefix=question\n",
        "            )\n",
        "        )\n",
        "        if len(human_feedback) == 0:\n",
        "            return resp.text\n",
        "        else:\n",
        "            task = f\"Based on the this resource html {text}, generate a blogpost about the topic in markdown format. Take into account previous feedback which was: {human_feedback}.\"\n",
        "            resp = chat_model.complete(task)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.agent.workflow import ReActAgent, AgentWorkflow, FunctionAgent\n",
        "\n",
        "\n",
        "llama_debug_handler = LlamaDebugHandler(print_trace_on_end=True)\n",
        "callback_manager = CallbackManager([llama_debug_handler])\n",
        "\n",
        "Settings.callback_manager = callback_manager\n",
        "\n",
        "web_search_tool = FunctionTool.from_defaults(\n",
        "    fn=get_relevant_webpages,\n",
        "    name=\"get_relevant_webpages\",\n",
        "    description=\"Useful for getting a url link to a relevant page for a particular query.\" \n",
        ")\n",
        "\n",
        "page_download_tool = FunctionTool.from_defaults(\n",
        "    fn=download_webpage,\n",
        "    name=\"download_webpage\",\n",
        "    description=\"Useful for dowloading raw html of the page, storing it in the agent's context and returning the content of that page.\"\n",
        ")\n",
        "\n",
        "blogpost_write_tool = FunctionTool.from_defaults(\n",
        "    fn=generate_blogpost,\n",
        "    name=\"generate_blogpost\",\n",
        "    description=\"Generate a blogpost based on the provided resource's html webpage.\"\n",
        ")\n",
        "\n",
        "search_agent = FunctionAgent(\n",
        "    name=\"WebSearcher\",\n",
        "    description=\"Search the web and provide a relevant link. Once you have the link, you must hand off control to the WebpageDownloader agent to download the page.\",\n",
        "    system_prompt=\"You are a WebSearcher. Your goal is to find relevant webpages for a given query. Once you have a sufficient list of URLs, you MUST hand off to the 'WebpageDownloader' agent to proceed with downloading the content. Your output should clearly indicate the list of URLs found.\",\n",
        "    tools=[web_search_tool],\n",
        "    verbose=True,\n",
        "    llm=chat_model,\n",
        "    can_handoff_to=[\"WebpageDownloader\"], \n",
        ")\n",
        "\n",
        "download_page_agent = FunctionAgent(\n",
        "    name=\"WebpageDownloader\",\n",
        "    description=\"Download a web page's html given a URL. Once the webpage is successfully downloaded, hand off control to the BlogpostWriter agent.\",\n",
        "    system_prompt=\"You are the WebpageDownloader. Your task is to download the raw HTML content of a given URL. After successfully downloading the page, you MUST hand off to the 'BlogpostWriter' agent, providing the downloaded HTML content for blog post generation.\",\n",
        "    tools=[page_download_tool],\n",
        "    verbose=True,\n",
        "    llm=chat_model,\n",
        "    can_handoff_to=[\"BlogpostWriter\"], \n",
        ")\n",
        "\n",
        "blogpost_writer_agent = FunctionAgent(\n",
        "    name=\"BlogpostWriter\",\n",
        "    description=\"Write a blogpost in markdown based on a resource's web page html. This is the final agent in the workflow.\",\n",
        "    system_prompt=\"You are the BlogpostWriter. Your job is to generate a comprehensive, modern, factual, and concise blogpost in markdown format using the provided raw HTML content of a webpage. Once the blogpost is generated and validated, you will provide the final answer.\",\n",
        "    tools=[blogpost_write_tool],\n",
        "    verbose=True,\n",
        "    llm=chat_model,\n",
        "    # No can_handoff_to for the final agent\n",
        ")\n",
        "\n",
        "workflow = AgentWorkflow(agents=[search_agent,download_page_agent,blogpost_writer_agent], root_agent=\"WebSearcher\")\n",
        "\n",
        "ctx = Context(workflow=workflow)\n",
        "handler = workflow.run(\"History of Prussia\", ctx=ctx)\n",
        "\n",
        "# async for event in handler.stream_events():\n",
        "#     if isinstance(event, InputRequiredEvent):\n",
        "#         response = input(event.prefix)\n",
        "#         handler.ctx.send_event(\n",
        "#             HumanResponseEvent(\n",
        "#                 response=response\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "# answer = await handler        \n",
        "# print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async for event in handler.stream_events():\n",
        "    print(event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
