{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pprint(text):\n",
        "    import textwrap\n",
        "    wrapped_text = textwrap.fill(text, width=100) \n",
        "    print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/maksim.rostov/pdev/freestyling/agents/hf-course/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "emb_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.llms.ollama import Ollama  \n",
        "\n",
        "chat_model = Ollama(model=\"qwen2:7b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnsDEuS1wHh-"
      },
      "source": [
        "## Researcher: An Agent Workflow\n",
        "\n",
        " 1) take a topic to write a blogpost about and subdivide it into sections\n",
        "Let's create an agent workflow that would: \n",
        " 2) The first section should define the variables, definitions, concepts and terminology that are going to be used for explaining (mathematicaly) the problem   \n",
        "    - Briefly explain those concepts if they are complicated \n",
        " 3) Look up websites that explain the topic  \n",
        "    - Download the selected websites and process their data (make a note that you need to refence them)\n",
        "    - Select websites that best fit the subsections identified before  \n",
        "    - Decide which website is the best at explaining the topic based on how it covers the subsections\n",
        "4) Analyse the website and change rearrange its content to fit the desired subsection structure and the variables and defintions  \n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.agent.workflow import ReActAgent, FunctionAgent\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.workflow import Context\n",
        "\n",
        "import mlflow\n",
        "\n",
        "mlflow.set_experiment(experiment_name=\"Test\")\n",
        "mlflow.set_tracking_uri('http://localhost:5000')\n",
        "mlflow.llama_index.autolog()\n",
        "\n",
        "\n",
        "def get_relevant_webpages(query: str) -> list:\n",
        "    \"\"\"\n",
        "    Gets the relevant webpages urls for a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): what to search online on www.\n",
        "\n",
        "    Returns:\n",
        "        list: list of url links (websites) related to the query \n",
        "    \"\"\"\n",
        "    search_ggg = DDGS()\n",
        "    results = search_ggg.text(query)\n",
        "    return results\n",
        "\n",
        "web_search_tool = FunctionTool.from_defaults(\n",
        "    fn=get_relevant_webpages,\n",
        "    name=\"get_relevant_webpages\",\n",
        "    description=\"Useful for getting a list of relevant webpages (url links) for a particular query. \" \\\n",
        "    \"Together with the web links the list also include a short information about the answer for the query.\"\n",
        ")\n",
        "\n",
        "search_agent = ReActAgent(\n",
        "    name = \"Web Searcher\", \n",
        "    description = \"Search the web give links to the relevant pages it found\",\n",
        "    system_prompt = \"\",\n",
        "    tools=[web_search_tool],\n",
        "    verbose=True,\n",
        "    llm=chat_model,\n",
        ")\n",
        "\n",
        "ctx = Context(search_agent)\n",
        "answer = await search_agent.run(\"History of Prussia, search online with the web search tool\", ctx=ctx)\n",
        "print(answer)\n",
        "pprint(answer.response.blocks[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
