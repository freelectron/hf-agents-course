{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70a55f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Any, Union\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    ")\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.tools import tool\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm import tqdm\n",
    "from langchain_core.messages import HumanMessage\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "import textwrap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0acbf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIALIZED_LOADERS = {\n",
    "    \".pdf\": PyPDFLoader,\n",
    "}\n",
    "\n",
    "# Configuration for chunking and embeddings\n",
    "CHUNK_SIZE = 2000  # Characters per chunk\n",
    "CHUNK_OVERLAP = 200  # Overlap between chunks\n",
    "\n",
    "REQUEST_TIMEOUT = 300\n",
    "CONTEXT_WINDOW = 80000\n",
    "MODEL_NAME = \"qwen2:7b\"\n",
    "\n",
    "FOLDERS_TO_EXCLUDE = [\".claude/\", \".conda\", \".gradio/\", \"__pycache__\", \".git\", \".DS_Store\"]\n",
    "\n",
    "class FailedToEmbed(Exception):\n",
    "    \"\"\" Raise when we failed to embed. \"\"\"\n",
    "    pass \n",
    "\n",
    "class FailedToChunk(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d87e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama initialized: Hello! How can I help you today? Let me know if yo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/6mkw37fs20q07p9x11q7d7k80000gq/T/ipykernel_78092/3067539600.py:17: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings model and text splitter initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ollama LLM for decision making and direct responses\n",
    "REQUEST_TIMEOUT = 300\n",
    "CONTEXT_WINDOW = 80000\n",
    "MODEL_NAME = \"qwen2:7b\"\n",
    "\n",
    "llm = Ollama(\n",
    "    model=MODEL_NAME, \n",
    "    context_window=CONTEXT_WINDOW, \n",
    "    request_timeout=REQUEST_TIMEOUT\n",
    ")\n",
    "\n",
    "# Test Ollama connection\n",
    "test_response = llm.complete(\"Hello\")\n",
    "print(f\"Ollama initialized: {test_response.text[:50]}...\")\n",
    "\n",
    "# Initialize HuggingFace embeddings model designed for longer inputs\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",  # Better for longer texts\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "# embeddings_model = HuggingFaceEmbeddings(\n",
    "#     model_name=\"Qwen/Qwen3-Embedding-8B\", \n",
    "#     encode_kwargs={'normalize_embeddings': True}\n",
    "# )\n",
    "# embeddings_model = HuggingFaceEmbeddings(\n",
    "#     model_name=\"intfloat/e5-mistral-7b-instruct\",\n",
    "#     encode_kwargs={\"normalize_embeddings\": True}\n",
    "# )\n",
    "# embeddings_model = HuggingFaceEmbeddings(\n",
    "#     model_name=\"nomic-ai/nomic-bert-2048\",\n",
    "#     encode_kwargs={\"normalize_embeddings\": True},\n",
    "#      model_kwargs={\"trust_remote_code\": True}\n",
    "# )\n",
    "\n",
    "\n",
    "# Initialize text splitter for chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "print(\"Embeddings model and text splitter initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02462345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files_from_directory(directory_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Scans a directory and returns a list of all file paths.\n",
    "    \"\"\"\n",
    "    all_files = []\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if not any(folder_to_exclude in file_path for folder_to_exclude in FOLDERS_TO_EXCLUDE):\n",
    "                all_files.append(file_path)\n",
    "    return all_files\n",
    "\n",
    "def load_process_documents(file_paths: List[str]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Loads documents from a list of file paths using the appropriate loader.\n",
    "    Defaults to TextLoader for any unrecognized file type.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        _, extension = os.path.splitext(file_path)\n",
    "        loader_class = SPECIALIZED_LOADERS.get(extension)\n",
    "\n",
    "        try:\n",
    "            if loader_class:\n",
    "                print(f\"Loading {file_path} with special loader..\")\n",
    "                loader = loader_class(file_path)\n",
    "            else:\n",
    "                # Default to TextLoader for all other files \n",
    "                loader = TextLoader(file_path, encoding='utf-8')\n",
    "            \n",
    "            doc = loader.load()[0]\n",
    "            processed_doc = chunk_and_embed_documents(doc)\n",
    "            \n",
    "            if doc is not None and doc.page_content is not None and processed_doc is not None:\n",
    "                documents.append(processed_doc)\n",
    "            else:\n",
    "                print(f\"Document with metadata skipped: {file_path}\")\n",
    "        except Exception as e:\n",
    "            # This will catch errors for true binary files that can't be decoded\n",
    "            print(f\"Skipping file {file_path}, could not be read as text. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    return documents\n",
    "\n",
    "def chunk_and_embed_documents(doc: Document) -> Document:\n",
    "    \"\"\"\n",
    "    Chunks large documents and creates averaged embeddings for each document.\n",
    "    If a document is small enough, uses it directly. If too large, chunks it\n",
    "    and averages the embeddings.\n",
    "    \"\"\"\n",
    "    processed_doc = None \n",
    "    if not doc.page_content.strip():\n",
    "        print(f\"Skipping empty document: {doc.metadata.get('source', 'N/A')}\")\n",
    "        return None \n",
    "        \n",
    "    try:\n",
    "        source_file = doc.metadata.get('source', 'N/A')\n",
    "        \n",
    "        # Check if document needs chunking\n",
    "        if len(doc.page_content) <= CHUNK_SIZE:\n",
    "            # Document is small enough, use as-is\n",
    "            avg_embedding = embeddings_model.embed_query(doc.page_content)\n",
    "            chunks = [doc.page_content]\n",
    "            print(f\"Document {source_file} is small enough, using directly\")\n",
    "        else:\n",
    "            # Document is too large, chunk it and average embeddings\n",
    "            chunks = text_splitter.split_text(doc.page_content)\n",
    "            print(f\"Document {source_file} chunked into {len(chunks)} pieces\")\n",
    "            \n",
    "            # Get embeddings for each chunk with progress bar\n",
    "            chunk_embeddings = []\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if chunk.strip():  # Skip empty chunks\n",
    "                    try:\n",
    "                        embedding = embeddings_model.embed_query(chunk)\n",
    "                        chunk_embeddings.append(np.array(embedding))\n",
    "                    except Exception as e:\n",
    "                        raise FailedToEmbed(f\"Error embedding chunk {i} of {source_file}: {e}\")\n",
    "            \n",
    "            if chunk_embeddings:\n",
    "                # Average the embeddings\n",
    "                avg_embedding = np.mean(chunk_embeddings, axis=0).tolist()\n",
    "                \n",
    "            else:\n",
    "                print(f\"Failed to create embeddings for {source_file}\")  \n",
    "    except Exception as e:\n",
    "        raise FailedToChunk(f\"Error processing document {doc.metadata.get('source', 'N/A')}: {e}\")\n",
    "\n",
    "    # Create a document with the original content but store the averaged embedding\n",
    "    # We'll store the embedding in metadata for later use\n",
    "    processed_doc = Document(\n",
    "        page_content=doc.page_content, \n",
    "        metadata={\n",
    "            **doc.metadata,\n",
    "            \"avg_embedding\": avg_embedding,  # Store as list for JSON serialization\n",
    "            \"num_chunks\": len(chunks)\n",
    "        }\n",
    "    )\n",
    "    return processed_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61730d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _index_logic(directory_path: str) -> Union[Qdrant, str]:\n",
    "    \"\"\"\n",
    "    Contains the core logic for the indexing process.\n",
    "    This function is called by the LangGraph tool.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(directory_path):\n",
    "        return f\"Error: The provided path '{directory_path}' is not a valid directory.\"\n",
    "\n",
    "    print(f\"Starting to process directory: {directory_path}\")\n",
    "\n",
    "    # 1. Get all files from the directory, regardless of extension\n",
    "    file_paths = get_all_files_from_directory(directory_path)\n",
    "    if not file_paths:\n",
    "        return \"No files found in the directory.\"\n",
    "    print(f\"Found {len(file_paths)} files to process.\")\n",
    "\n",
    "    # 2. Load the content of all readable documents\n",
    "    processed_docs = load_process_documents(file_paths)\n",
    "    if not processed_docs:\n",
    "        return \"Could not load any readable text content from the files found.\"\n",
    "    print(f\"Successfully loaded content from {len(processed_docs)} readable files.\")\n",
    "    \n",
    "    # 3. Create vector store using pre-computed embeddings\n",
    "    try:\n",
    "        from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "        import uuid\n",
    "\n",
    "        client = QdrantClient(\":memory:\")\n",
    "        collection_name = \"directory_documents\"\n",
    "\n",
    "        # Create collection with vector config\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=VectorParams(size=len(processed_docs[0].metadata[\"avg_embedding\"]), distance=Distance.COSINE)\n",
    "        )\n",
    "\n",
    "        # Add documents with pre-computed embeddings using PointStruct\n",
    "        points = []\n",
    "        for i, doc in enumerate(processed_docs):\n",
    "            # Remove avg_embedding from metadata to avoid duplication\n",
    "            clean_metadata = {k: v for k, v in doc.metadata.items() if k != \"avg_embedding\"}\n",
    "            \n",
    "            point = PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=doc.metadata[\"avg_embedding\"],\n",
    "                payload={\"page_content\": doc.page_content, **clean_metadata}\n",
    "            )\n",
    "            points.append(point)\n",
    "\n",
    "        client.upsert(collection_name=collection_name, points=points)\n",
    "        print(\"Successfully created Qdrant vector store using pre-computed embeddings.\")\n",
    "        \n",
    "        qdrant = Qdrant(\n",
    "            client=client,\n",
    "            collection_name=collection_name,\n",
    "            embeddings=embeddings_model\n",
    "        ) \n",
    "        return qdrant\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while creating the Qdrant vector store: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to store the vector store for reuse\n",
    "global_vector_store = None\n",
    "\n",
    "@tool\n",
    "def index_directory(directory_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Processes all readable files in a directory using chunking strategy for large files\n",
    "    and averaged embeddings. No LLM calls during indexing - only HuggingFace embeddings.\n",
    "    Args:\n",
    "        directory_path: The absolute path to the directory to be indexed.\n",
    "    Returns:\n",
    "        A success or error message.\n",
    "    \"\"\"\n",
    "    global global_vector_store\n",
    "    result = _index_logic(directory_path)\n",
    "    if isinstance(result, str):\n",
    "        return result  # Return error message\n",
    "    else:\n",
    "        # Store the vector store globally for the RAG tool to use\n",
    "        global_vector_store = result\n",
    "        return f\"Successfully processed directory '{directory_path}'. Documents are now indexed with chunked embeddings.\"\n",
    "\n",
    "@tool\n",
    "def search_documents(query: str, k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search through the indexed documents using semantic similarity.\n",
    "    Args:\n",
    "        query: The search query\n",
    "        k: Number of results to return (default 5)\n",
    "    Returns:\n",
    "        Search results with file paths and relevant content\n",
    "    \"\"\"\n",
    "    global global_vector_store\n",
    "    \n",
    "    if global_vector_store is None:\n",
    "        return \"No documents have been indexed yet. Please run index_directory first.\"\n",
    "    \n",
    "    try:\n",
    "        search_results = global_vector_store.similarity_search(query, k=k)\n",
    "        \n",
    "        if not search_results:\n",
    "            return f\"No relevant documents found for query: '{query}'\"\n",
    "        \n",
    "        results_text = f\"Found {len(search_results)} relevant documents for query: '{query}'\\n\\n\"\n",
    "        \n",
    "        for i, doc in enumerate(search_results, 1):\n",
    "            source = doc.metadata.get('source', 'Unknown')\n",
    "            content_preview = doc.page_content[:500] + \"...\"\n",
    "            num_chunks = doc.metadata.get('num_chunks', 'N/A')\n",
    "            \n",
    "            results_text += f\"Result {i}:\\n\"\n",
    "            results_text += f\"File: {source}\\n\"\n",
    "            if num_chunks != 'N/A':\n",
    "                results_text += f\"Chunks: {num_chunks}\\n\"\n",
    "            results_text += f\"Content: {content_preview}\\n\"\n",
    "            results_text += \"-\" * 80 + \"\\n\\n\"\n",
    "        \n",
    "        return results_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error searching documents: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720108ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Agent with LLM-based decision making created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the state for our agent\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    query: str\n",
    "    search_results: str\n",
    "    needs_local_knowledge: bool\n",
    "\n",
    "# Decision function using Ollama LLM\n",
    "def decide_knowledge_source(state: AgentState) -> str:\n",
    "    \"\"\"Use Ollama LLM to decide if the question requires local knowledge from vector store\"\"\"\n",
    "    query = state[\"messages\"][-1].content\n",
    "    \n",
    "    decision_prompt = f\"\"\"You are an intelligent assistant that determines whether a user's question requires local knowledge from a vector database containing files and documents from a directory, or if it can be answered with general knowledge.\n",
    "\n",
    "User Question: \"{query}\"\n",
    "\n",
    "Consider the following:\n",
    "- Questions about specific files, code, implementations, or content within a directory require LOCAL KNOWLEDGE\n",
    "- Questions about general concepts, explanations, tutorials, or broad topics can be answered with GENERAL KNOWLEDGE\n",
    "- Questions asking \"what is in this directory\", \"show me files\", \"explain this code\" require LOCAL KNOWLEDGE\n",
    "- Questions like \"what is Python?\", \"how does machine learning work?\", \"explain REST APIs\" need GENERAL KNOWLEDGE\n",
    "\n",
    "Respond with EXACTLY one word: either \"LOCAL\" or \"GENERAL\"\n",
    "\n",
    "Decision:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = llm.complete(decision_prompt)\n",
    "        decision = response.text.strip().upper()\n",
    "        \n",
    "        if \"LOCAL\" in decision:\n",
    "            return \"use_vector_store\"\n",
    "        else:\n",
    "            return \"direct_response\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in decision making: {e}\")\n",
    "        return \"use_vector_store\"\n",
    "\n",
    "def search_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Search for relevant documents in vector store\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    search_results = search_documents(query)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"],\n",
    "        \"query\": query,\n",
    "        \"search_results\": search_results,\n",
    "        \"needs_local_knowledge\": True\n",
    "    }\n",
    "\n",
    "def vector_response_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate response using vector store search results\"\"\"\n",
    "    query = state[\"messages\"][-1].content\n",
    "    search_results = state.get(\"search_results\", \"\")\n",
    "    \n",
    "    if search_results and \"No relevant documents found\" not in search_results:\n",
    "        # Use Ollama to generate a response based on the search results\n",
    "        response_prompt = f\"\"\"Based on the following search results from local files and documents, answer the user's question comprehensively.\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Search Results:\n",
    "{search_results}\n",
    "\n",
    "Please provide a helpful answer based on the information found in the local documents. If the search results don't fully answer the question, say so and provide what information is available.\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            ollama_response = llm.complete(response_prompt)\n",
    "            response_content = f\"Based on the local documents:\\n\\n{ollama_response.text}\"\n",
    "        except Exception as e:\n",
    "            response_content = f\"Found local documents but error generating response: {e}\\n\\nRaw search results:\\n{search_results}\"\n",
    "    else:\n",
    "        response_content = \"No relevant documents found in the local directory for your question.\"\n",
    "    \n",
    "    from langchain_core.messages import AIMessage\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=response_content)],\n",
    "        \"query\": query,\n",
    "        \"search_results\": search_results,\n",
    "        \"needs_local_knowledge\": True\n",
    "    }\n",
    "\n",
    "def direct_response_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate direct response using Ollama without vector store\"\"\"\n",
    "    query = state[\"messages\"][-1].content\n",
    "    \n",
    "    try:\n",
    "        # Direct response from Ollama for general knowledge questions\n",
    "        response = llm.complete(query)\n",
    "        response_content = response.text\n",
    "    except Exception as e:\n",
    "        response_content = f\"Error generating response: {e}\"\n",
    "    \n",
    "    from langchain_core.messages import AIMessage\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=response_content)],\n",
    "        \"query\": query,\n",
    "        \"search_results\": \"\",\n",
    "        \"needs_local_knowledge\": False\n",
    "    }\n",
    "\n",
    "def route_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"Initial routing step\"\"\"\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"],\n",
    "        \"query\": state[\"messages\"][-1].content,\n",
    "        \"search_results\": \"\",\n",
    "        \"needs_local_knowledge\": False\n",
    "    }\n",
    "\n",
    "# Create the LangGraph with improved decision making\n",
    "def create_rag_agent():\n",
    "    \"\"\"Create a LangGraph agent with LLM-based decision making\"\"\"\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"route\", route_query)\n",
    "    workflow.add_node(\"search\", search_step)\n",
    "    workflow.add_node(\"vector_response\", vector_response_step)\n",
    "    workflow.add_node(\"direct_response\", direct_response_step)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"route\")\n",
    "    \n",
    "    # Add conditional edges from route using LLM decision\n",
    "    workflow.add_conditional_edges(\n",
    "        \"route\",\n",
    "        decide_knowledge_source,  # LLM-based decision function\n",
    "        {\n",
    "            \"use_vector_store\": \"search\",\n",
    "            \"direct_response\": \"direct_response\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # After search, go to vector response\n",
    "    workflow.add_edge(\"search\", \"vector_response\")\n",
    "    \n",
    "    # Both response types end the workflow\n",
    "    workflow.add_edge(\"vector_response\", END)\n",
    "    workflow.add_edge(\"direct_response\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Create the agent\n",
    "rag_agent = create_rag_agent()\n",
    "\n",
    "print(\"RAG Agent with LLM-based decision making created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4eu3oz0ub",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAG Agent Workflow Diagram ===\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow diagram displayed above.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== RAG Agent Workflow Diagram ===\")\n",
    "\n",
    "try:\n",
    "    # Generate and display the workflow diagram\n",
    "    from IPython.display import Image, display\n",
    "    \n",
    "    # Get the diagram as PNG bytes\n",
    "    diagram_png = rag_agent.get_graph().draw_mermaid_png()\n",
    "    \n",
    "    # Display the diagram\n",
    "    display(Image(diagram_png))\n",
    "    print(\"Workflow diagram displayed above.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not generate diagram: {e}\")\n",
    "    \n",
    "    # Fallback: print text representation of the workflow\n",
    "    print(\"\\nWorkflow Structure (Text):\")\n",
    "    print(\"1. route (entry point)\")\n",
    "    print(\"2. decide_knowledge_source() -> LOCAL or GENERAL\")\n",
    "    print(\"3a. If LOCAL: search -> vector_response -> END\")\n",
    "    print(\"3b. If GENERAL: direct_response -> END\")\n",
    "    print(\"\\nNodes:\")\n",
    "    print(\"- route: Initial query processing\")\n",
    "    print(\"- search: Vector database search\")\n",
    "    print(\"- vector_response: LLM response with search results\")\n",
    "    print(\"- direct_response: Direct LLM response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861739a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing directory...\n",
      "Starting to process directory: ../unit2.3_langgraph\n",
      "Found 6 files to process.\n",
      "Document ../unit2.3_langgraph/researcher_v5.ipynb chunked into 62 pieces\n",
      "Document ../unit2.3_langgraph/researcher_v3.ipynb chunked into 50 pieces\n",
      "Document ../unit2.3_langgraph/researcher_v1.ipynb chunked into 5 pieces\n",
      "Document ../unit2.3_langgraph/research_output_v5_2025_08_08_17_36.md chunked into 2 pieces\n",
      "Document ../unit2.3_langgraph/researcher_v2.ipynb chunked into 214 pieces\n",
      "Document ../unit2.3_langgraph/research_output_v5_2025_08_08_17_36_final.md chunked into 2 pieces\n",
      "Successfully loaded content from 6 readable files.\n",
      "Successfully created Qdrant vector store using pre-computed embeddings.\n",
      "Successfully processed directory '../unit2.3_langgraph'. Documents are now indexed with chunked embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/6mkw37fs20q07p9x11q7d7k80000gq/T/ipykernel_78092/625384571.py:53: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
      "  qdrant = Qdrant(\n"
     ]
    }
   ],
   "source": [
    "# First, index a directory \n",
    "print(\"Indexing directory...\")\n",
    "result = index_directory(\"../unit2.3_langgraph\")\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb41f9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'_id': '152a7549-e02b-44bb-b951-67cb1787790e', '_collection_name': 'directory_documents'}, page_content='{\\n  \"cells\": [\\n    {\\n      \"cell_type\": \"markdown\",\\n      \"metadata\": {},\\n      \"source\": [\\n        \"## LLMs\"\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"execution_count\": null,\\n      \"metadata\": {},\\n      \"outputs\": [],\\n      \"source\": [\\n        \"from llama_index.llms.ollama import Ollama  \\\\n\",\\n        \"\\\\n\",\\n        \"chat_model = Ollama(model=\\\\\"qwen2:7b\\\\\", context_window=80000, request_timeout=300)\"\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"markdown\",\\n      \"metadata\": {\\n        \"id\": \"dnsDEuS1wHh-\"\\n      },\\n      \"source\": [\\n        \"## Researcher: An Agent Workflow\\\\n\",\\n        \"\\\\n\",\\n        \"Let\\'s create an agent workflow that would: \\\\n\",\\n        \"defintions  \\\\n\",\\n        \"     \"\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"execution_count\": null,\\n      \"metadata\": {},\\n      \"outputs\": [],\\n      \"source\": [\\n        \"from bs4 import BeautifulSoup\\\\n\",\\n        \"\\\\n\",\\n        \"def extract_text_with_beautifulsoup(raw_html: str) -> str:\\\\n\",\\n        \"    \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"    Extract clean text from raw HTML using BeautifulSoup.\\\\n\",\\n        \"    \\\\n\",\\n        \"    Args:\\\\n\",\\n        \"        raw_html (str): Raw HTML content\\\\n\",\\n        \"        \\\\n\",\\n        \"    Returns:\\\\n\",\\n        \"        str: Extracted clean text\\\\n\",\\n        \"    \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"    soup = BeautifulSoup(raw_html, \\'html.parser\\')\\\\n\",\\n        \"    \\\\n\",\\n        \"    # Remove script and style elements\\\\n\",\\n        \"    for script in soup([\\\\\"script\\\\\", \\\\\"style\\\\\", \\\\\"nav\\\\\", \\\\\"footer\\\\\", \\\\\"header\\\\\", \\\\\"aside\\\\\"]):\\\\n\",\\n        \"        script.decompose()\\\\n\",\\n        \"    \\\\n\",\\n        \"    # Get text and clean it up\\\\n\",\\n        \"    text = soup.get_text()\\\\n\",\\n        \"    \\\\n\",\\n        \"    # Clean up whitespace\\\\n\",\\n        \"    lines = (line.strip() for line in text.splitlines())\\\\n\",\\n        \"    chunks = (phrase.strip() for line in lines for phrase in line.split(\\\\\"  \\\\\"))\\\\n\",\\n        \"    text = \\' \\'.join(chunk for chunk in chunks if chunk)\\\\n\",\\n        \"    \\\\n\",\\n        \"    return text\\\\n\"\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"execution_count\": null,\\n      \"metadata\": {},\\n      \"outputs\": [],\\n      \"source\": [\\n        \"from typing import TypedDict, Optional\\\\n\",\\n        \"from datetime import datetime\\\\n\",\\n        \"\\\\n\",\\n        \"import urllib\\\\n\",\\n        \"\\\\n\",\\n        \"# import mlflow\\\\n\",\\n        \"# mlflow.set_experiment(experiment_name=datetime.now().isoformat())\\\\n\",\\n        \"# mlflow.set_tracking_uri(\\'http://localhost:5000\\')\\\\n\",\\n        \"# mlflow.llama_index.autolog()\\\\n\",\\n        \"\\\\n\",\\n        \"\\\\n\",\\n        \"class SearchState(TypedDict):\\\\n\",\\n        \"    # Query to research\\\\n\",\\n        \"    query: str \\\\n\",\\n        \"\\\\n\",\\n        \"    # List of relevant urls webpages (resources/references) to the query \\\\n\",\\n        \"    web_urls: Optional[list[str]] \\\\n\",\\n        \"\\\\n\",\\n        \"    # Current url that is being dowloaded processed \\\\n\",\\n        \"    url: Optional[str] \\\\n\",\\n        \"\\\\n\",\\n        \"    # Retrieved text from from respective urls websources \\\\n\",\\n        \"    text_sources: Optional[list[str]]  \\\\n\",\\n        \"\\\\n\",\\n        \"    # Final output blogpost\\\\n\",\\n        \"    post: str\\\\n\",\\n        \"\\\\n\",\\n        \"\\\\n\",\\n        \"def get_relevant_webpages(state: SearchState):\\\\n\",\\n        \"    \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"    Gets the url of the most relevant webpages for the query.\\\\n\",\\n        \"\\\\n\",\\n        \"    Args:\\\\n\",\\n        \"        query (str): what to search online on www.\\\\n\",\\n        \"\\\\n\",\\n        \"    Returns:\\\\n\",\\n        \"        str: url link.\\\\n\",\\n        \"    \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"    from ddgs import DDGS\\\\n\",\\n        \"\\\\n\",\\n        \"    search_ggg = DDGS()\\\\n\",\\n        \"    results = search_ggg.text(query=state[\\\\\"query\\\\\"], max_results=2)\\\\n\",\\n        \"    state[\\\\\"web_urls\\\\\"] = [res[\\\\\"href\\\\\"] for res in results]\\\\n\",\\n        \"    \\\\n\",\\n        \"    return state\\\\n\",\\n        \"\\\\n\",\\n        \"def check_urls(state: SearchState):\\\\n\",\\n        \"    \\\\\"\\\\\"\\\\\"There could be complex comparison logic here, but we just implement this in `route_move_to_download`.\\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"    return state\\\\n\",\\n        \"    \\\\n\",\\n        \"def route_move_to_download(state: SearchState): \\\\n\",\\n        \"    if len(state[\\\\\"web_urls\\\\\"])>0:\\\\n\",\\n        \"        return \\\\\"proceed\\\\\"\\\\n\",\\n        \"    else:\\\\n\",\\n        \"        return \\\\\"stop\\\\\"\\\\n\",\\n        \"\\\\n\",\\n        \"def download_webpages(state: SearchState) -> str:\\\\n\",\\n        \"    \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"    Load the raw webpage of the url. Store it in the context.\\\\n\",\\n        \"    \\\\n\",\\n        \"    Args:\\\\n\",\\n        \"        url (str): www url of the page.\\\\n\",\\n        \"    \\\\n\",\\n        \"    Returns: \\\\n\",\\n        \"        str: html string of the text on the webpage.\\\\n\",\\n        \"    \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"\\\\n\",\\n        \"    for url in state[\\\\\"web_urls\\\\\"]:\\\\n\",\\n        \"        try: \\\\n\",\\n        \"            with urllib.request.urlopen(url) as response:\\\\n\",\\n        \"                html_text = response.read()\\\\n\",\\n        \"                state[\\\\\"text_sources\\\\\"].append(extract_text_with_beautifulsoup(html_text))\\\\n\",\\n        \"        except urllib.error.URLError as e:\\\\n\",\\n        \"            print(\\\\\"Error getting the page: \\\\\", e)\\\\n\",\\n        \"        except Exception as e:\\\\n\",\\n        \"            print(\\\\\"Something happened: \\\\\", e)\\\\n\",\\n        \"    \\\\n\",\\n        \"    return state\\\\n\",\\n        \"\\\\n\",\\n        \"def generate_blogpost(state:SearchState) -> str:\\\\n\",\\n        \"    \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"    Generate a blogpost in a markdown format based on the raw of a resource. \\\\n\",\\n        \"    \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"    # TODO: how to use all the resources? \\\\n\",\\n        \"    sources = state[\\\\\"text_sources\\\\\"][0]\\\\n\",\\n        \"    task = f\\\\\"Based on the this information {sources}, generate a blogpost about the topic {state[\\'query\\']} in the markdown format.\\\\\"\\\\n\",\\n        \"    state[\\\\\"post\\\\\"] = chat_model.complete(task)\\\\n\",\\n        \"\\\\n\",\\n        \"    return state\"\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"execution_count\": null,\\n      \"metadata\": {},\\n      \"outputs\": [],\\n      \"source\": [\\n        \"from langgraph.graph import StateGraph, START, END\\\\n\",\\n        \"from IPython.display import Image, display\\\\n\",\\n        \"\\\\n\",\\n        \"# Create the graph\\\\n\",\\n        \"researcher_graph = StateGraph(SearchState)\\\\n\",\\n        \"\\\\n\",\\n        \"# Add nodes\\\\n\",\\n        \"researcher_graph.add_node(\\\\\"get_relevant_webpages\\\\\", get_relevant_webpages)\\\\n\",\\n        \"researcher_graph.add_node(\\\\\"check_urls\\\\\", check_urls)\\\\n\",\\n        \"researcher_graph.add_node(\\\\\"download_webpages\\\\\", download_webpages)\\\\n\",\\n        \"researcher_graph.add_node(\\\\\"generate_blogpost\\\\\", generate_blogpost)\\\\n\",\\n        \"\\\\n\",\\n        \"researcher_graph.add_edge(START, \\\\\"get_relevant_webpages\\\\\")\\\\n\",\\n        \"researcher_graph.add_edge(\\\\\"get_relevant_webpages\\\\\", \\\\\"check_urls\\\\\")\\\\n\",\\n        \"researcher_graph.add_conditional_edges(\\\\n\",\\n        \"    \\\\\"check_urls\\\\\",\\\\n\",\\n        \"    route_move_to_download,\\\\n\",\\n        \"    {\\\\n\",\\n        \"        \\\\\"proceed\\\\\": \\\\\"download_webpages\\\\\",\\\\n\",\\n        \"        \\\\\"stop\\\\\": END\\\\n\",\\n        \"    }\\\\n\",\\n        \")\\\\n\",\\n        \"researcher_graph.add_edge(\\\\\"download_webpages\\\\\", \\\\\"generate_blogpost\\\\\")\\\\n\",\\n        \"researcher_graph.add_edge(\\\\\"generate_blogpost\\\\\", END)\\\\n\",\\n        \"\\\\n\",\\n        \"dag = researcher_graph.compile()\\\\n\",\\n        \"display(Image(dag.get_graph().draw_mermaid_png()))\"\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"execution_count\": null,\\n      \"metadata\": {},\\n      \"outputs\": [],\\n      \"source\": [\\n        \"init_state = SearchState(query=\\\\\"History of Prussia\\\\\", text_sources=list())\\\\n\",\\n        \"res = dag.invoke(init_state)\"\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"execution_count\": null,\\n      \"metadata\": {},\\n      \"outputs\": [],\\n      \"source\": [\\n        \"# import pprint\\\\n\",\\n        \"# # Set width to control line length (e.g., 80 characters)\\\\n\",\\n        \"# pp = pprint.PrettyPrinter(width=80, depth=4)\\\\n\",\\n        \"# pp.pprint(res)\"\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"execution_count\": null,\\n      \"metadata\": {},\\n      \"outputs\": [],\\n      \"source\": [\\n        \"print(res[\\\\\"post\\\\\"].text)\\\\n\",\\n        \"with open(f\\\\\"post_{datetime.now().strftime(\\'%Y_%m_%d_%H_%M\\')}.md\\\\\", \\\\\"w\\\\\") as f:\\\\n\",\\n        \"    f.write(res[\\\\\"post\\\\\"].text)\\\\n\"\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"execution_count\": null,\\n      \"metadata\": {},\\n      \"outputs\": [],\\n      \"source\": []\\n    },\\n    {\\n      \"cell_type\": \"markdown\",\\n      \"metadata\": {},\\n      \"source\": []\\n    }\\n  ],\\n  \"metadata\": {\\n    \"colab\": {\\n      \"provenance\": []\\n    },\\n    \"kernelspec\": {\\n      \"display_name\": \"Python 3\",\\n      \"language\": \"python\",\\n      \"name\": \"python3\"\\n    },\\n    \"language_info\": {\\n      \"codemirror_mode\": {\\n        \"name\": \"ipython\",\\n        \"version\": 3\\n      },\\n      \"file_extension\": \".py\",\\n      \"mimetype\": \"text/x-python\",\\n      \"name\": \"python\",\\n      \"nbconvert_exporter\": \"python\",\\n      \"pygments_lexer\": \"ipython3\",\\n      \"version\": \"3.12.10\"\\n    }\\n  },\\n  \"nbformat\": 4,\\n  \"nbformat_minor\": 0\\n}\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_payloads = []\n",
    "# while True:\n",
    "#     points, offset = global_vector_store.client.scroll(\n",
    "#         collection_name=global_vector_store.collection_name,\n",
    "#         with_payload=True,\n",
    "#     )\n",
    "#     all_payloads.extend([p.payload for p in points])\n",
    "#     if offset is None:\n",
    "#         break\n",
    "#     print([p.payload for p in points])\n",
    "\n",
    "# all_payloads[:2]\n",
    "search_results = global_vector_store.similarity_search(\"Detail analyis on researchers_v1 file\", k=4)\n",
    "search_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2982c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311840b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1.1: Local knowledge question (should use vector store)\n",
    "print(\"\\n--- Test 1: Local Knowledge Question ---\")\n",
    "local_query = \"What researcher file version should I use to be able to have an agent with tools?\"\n",
    "local_state = {\n",
    "    \"messages\": [HumanMessage(content=local_query)],\n",
    "    \"query\": \"\",\n",
    "    \"search_results\": \"\",\n",
    "    \"needs_local_knowledge\": False\n",
    "}\n",
    "\n",
    "result = rag_agent.invoke(local_state)\n",
    "print(f\"Query: {local_query}\")\n",
    "print(textwrap.fill(f\"Response: {result['messages'][-1]}\", width=160))\n",
    "print(f\"Used local knowledge: {result['needs_local_knowledge']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "becb3b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test 1: Local Knowledge Question ---\n",
      "Query: Analysise researcher_v1 file\n",
      "Response: content='Based on the local documents:\\n\\nThe researcher_v1 file contains code related to the implementation or usage of an LLM (Language Model).\n",
      "Specifically, it involves importing a Python module named `llm_index` which provides an interface to interact with AI models for tasks such as text generation.\n",
      "The code uses Ollama, a language model from the \"qwen2:7b\" model class, setting its context window size to 80,000 characters and configuring it to handle\n",
      "requests within a timeout of 300 seconds.\\n\\nAdditionally, the researcher_v1 file seems to describe various workflows for enhancing or refining research agent\n",
      "operations. These include:\\n\\n1. **Planning Sections**: Based on user queries, this part likely involves structuring content into manageable sections.\\n2.\n",
      "**Finding Relevant Web Sources**: This section might cover methods of discovering pertinent internet resources related to each planning section.\\n3.\n",
      "**Downloading and Processing Content**: The process includes gathering information from the identified web sources and transforming it for use in the research\n",
      "agent\\'s output.\\n4. **Generating Comprehensive Blog Post Sections**: Using AI tools, this involves creating detailed sections that contribute to a cohesive\n",
      "blog post.\\n\\nThe most recent iteration mentioned is \"Researcher Agent v5\", which extends upon these features with an additional step: **Human Review and\n",
      "Editing**. This suggests that after the AI processes information and generates content, human oversight intervenes to refine or correct the output before it\\'s\n",
      "finalized.\\n\\nHowever, details about specific functionalities of researcher_v1 are limited in this context as most results mention later versions of similar\n",
      "systems (such as v5). Therefore, while we understand some of the workflows involved based on descriptions from v3 and v5, there might be additional features\n",
      "unique to researcher_v1 that aren\\'t fully captured by these results.' additional_kwargs={} response_metadata={} id='cf64ea76-5e6c-4350-b679-235784526088'\n",
      "Used local knowledge: True\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 1.2: Local knowledge question (should use vector store)\n",
    "print(\"\\n--- Test 1: Local Knowledge Question ---\")\n",
    "local_query = \"Analysise researcher_v1 file\"\n",
    "local_state = {\n",
    "    \"messages\": [HumanMessage(content=local_query)],\n",
    "    \"query\": \"\",\n",
    "    \"search_results\": \"\",\n",
    "    \"needs_local_knowledge\": False\n",
    "}\n",
    "\n",
    "result = rag_agent.invoke(local_state)\n",
    "print(f\"Query: {local_query}\")\n",
    "print(textwrap.fill(f\"Response: {result['messages'][-1]}\", width=160))\n",
    "print(f\"Used local knowledge: {result['needs_local_knowledge']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: General knowledge question (should use direct Ollama)\n",
    "print(\"\\n--- Test 2: General Knowledge Question ---\")\n",
    "general_query = \"Explain history of Prussia briefly.\"\n",
    "general_state = {\n",
    "    \"messages\": [HumanMessage(content=general_query)],\n",
    "    \"query\": \"\",\n",
    "    \"search_results\": \"\",\n",
    "    \"needs_local_knowledge\": False\n",
    "}\n",
    "\n",
    "result = rag_agent.invoke(general_state)\n",
    "print(f\"Query: {general_query}\")\n",
    "print(f\"Response: {result['messages'][-1]}...\")\n",
    "print(f\"Used local knowledge: {result['needs_local_knowledge']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7da3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test 3: Ambiguous question to test decision making\n",
    "print(\"\\n--- Test 3: Ambiguous Question ---\")\n",
    "ambiguous_query = \"How do I implement a function?\"\n",
    "ambiguous_state = {\n",
    "    \"messages\": [HumanMessage(content=ambiguous_query)],\n",
    "    \"query\": \"\",\n",
    "    \"search_results\": \"\",\n",
    "    \"needs_local_knowledge\": False\n",
    "}\n",
    "\n",
    "result = rag_agent.invoke(ambiguous_state)\n",
    "print(f\"Query: {ambiguous_query}\")\n",
    "print(f\"Response: {result['messages'][-1]}...\")\n",
    "print(f\"Used local knowledge: {result['needs_local_knowledge']}\")\n",
    "\n",
    "print(\"\\n=== Enhanced RAG System Test Complete ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
