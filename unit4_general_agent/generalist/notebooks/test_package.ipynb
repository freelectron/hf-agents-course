{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from generalist.agents.core import CapabilityPlan\n",
    "from generalist.tools.data_model import Attachments, ContentResource, ShortAnswer, Task\n",
    "\n",
    "\n",
    "class ExecutionState(TypedDict):\n",
    "    # what user is asking to do for them \n",
    "    ask: str\n",
    "    # Identifies what the original question/task given, which objective it got transferred to, what the plan to get an answer is\n",
    "    task: Task\n",
    "    # order index of the step of the task's plan that is being executed \n",
    "    step: int\n",
    "    # clues, findings and answers to the previous subtasks \n",
    "    context: str  \n",
    "    # capability plan for this task (overwritten when a new subtask from the main plain is picked up)\n",
    "    capability_plan: CapabilityPlan\n",
    "    # capability plan step order \n",
    "    capability_plan_step: int\n",
    "    # answers to subtask, the last one should be the final answer to the task \n",
    "    answers: list[ShortAnswer]\n",
    "    # all files that might be needed to execute the task \n",
    "    attachments: list[Attachments]\n",
    "    # all text resources that might be needed to execute the task\n",
    "    resources: list[ContentResource]\n",
    "    # tools that already got called\n",
    "    # TODO: see if this is needed \n",
    "    tools_called: str  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695079d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from generalist.agents.core import AgentCapabilityDeepWebSearch, AgentCapabilityUnstructuredDataProcessor\n",
    "from generalist.tools.planning import determine_capabilities, create_plan\n",
    "from generalist.tools.summarisers import construct_short_answer\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=ExecutionState)\n",
    "\n",
    "def init_state(ask: str, attachments: str = None, resources: str = None) -> ExecutionState:\n",
    "    # TODO: should I be using LLM to convert attachments/resources to acceptable format?\n",
    "    # TODO: implement proper handling of attachments and resources \n",
    "    return ExecutionState(\n",
    "        ask=ask,\n",
    "        task=None,\n",
    "        step=None,\n",
    "        context=\"\",\n",
    "        answers=list(),\n",
    "        resources=list(),\n",
    "        attachments=list(),\n",
    "    )\n",
    "\n",
    "def set_task(state: ExecutionState) -> ExecutionState: \n",
    "    question_task = state[\"ask\"]\n",
    "    task_plan_response = create_plan(question_task)\n",
    "\n",
    "    result = json.loads(task_plan_response)\n",
    "    task = Task(\n",
    "      question=question_task,\n",
    "      objective=result[\"objective\"],\n",
    "      plan=result[\"plan\"],\n",
    "    )\n",
    "    state[\"task\"] = task\n",
    "\n",
    "    return state\n",
    "\n",
    "def set_plan_step(state: ExecutionState) -> ExecutionState: \n",
    "    \"\"\"  \n",
    "    Determine which state is being executed. \n",
    "    \"\"\"\n",
    "    if state[\"step\"] is None: \n",
    "        state[\"step\"] = 0 \n",
    "    else:\n",
    "        state[\"step\"] += 1\n",
    "         \n",
    "    return state\n",
    "\n",
    "def check_plan_completion(state: ExecutionState) -> str:\n",
    "    # FIXME: see what to do with the showrt_anser var, now only for debugging \n",
    "    short_answer = construct_short_answer(state[\"task\"].objective, state[\"context\"])\n",
    "    print(\"\\nCurrent answer is:\\n\", short_answer, \"\\n\")\n",
    "    # TODO: might incorporate early stopping if answer is found\n",
    "    # if not short_answer | len(short_answer.answer) == 0 | short_answer.answer.lower() != \"not found\":\n",
    "        \n",
    "    plan_length = len(state[\"task\"].plan)\n",
    "    if state[\"step\"] < plan_length:\n",
    "        return \"proceed\"\n",
    "    else:\n",
    "        return \"stop\"\n",
    "\n",
    "def set_capability_plan(state: ExecutionState) -> ExecutionState: \n",
    "    state[\"capability_plan\"] = determine_capabilities(\n",
    "        state[\"task\"].plan[state[\"step\"]], \n",
    "        task=state[\"task\"], \n",
    "        attachments=state[\"attachments\"], \n",
    "        context=state[\"context\"]\n",
    "    )\n",
    "    state[\"capability_plan_step\"] = 0\n",
    "\n",
    "    return state\n",
    "\n",
    "def set_capability_step(state: ExecutionState) -> ExecutionState:\n",
    "    if state[\"capability_plan_step\"] is None:\n",
    "        state[\"capability_plan_step\"] = 0 \n",
    "    else:\n",
    "        state[\"capability_plan_step\"] += 1 \n",
    "\n",
    "    return state\n",
    "\n",
    "def check_capability_step(state:ExecutionState) -> ExecutionState: \n",
    "    capability_plan_length = len(state[\"capability_plan\"].subplan)\n",
    "    if state[\"capability_plan_step\"] < capability_plan_length:\n",
    "        # run the next capability step\n",
    "        return \"iterate\"        \n",
    "    else: \n",
    "        # signal that we need to move over to the next state\n",
    "        return \"stop\" \n",
    "\n",
    "def run_capability(state: ExecutionState) -> ExecutionState: \n",
    "    capability_agent = state[\"capability_plan\"].subplan[state[\"capability_plan_step\"]]\n",
    "    output = None\n",
    "    match capability_agent:\n",
    "        case AgentCapabilityDeepWebSearch():\n",
    "            output = capability_agent.run()\n",
    "        case AgentCapabilityUnstructuredDataProcessor():\n",
    "            output = capability_agent.run(state[\"resources\"])\n",
    "        case _:\n",
    "            print(\"DEBUG | run_capability | Call to unidentified agent: \", capability_agent)\n",
    "    answers = output.answers\n",
    "    resources = output.resources\n",
    "    attachments = output.attachments \n",
    "\n",
    "    # FIXME: delete this  \n",
    "    print(\"DEBUG | run_capability | Reponse output: \", output)\n",
    "\n",
    "    if answers:\n",
    "        state[\"answers\"].extend(answers)\n",
    "    if attachments:\n",
    "        state[\"attachments\"].extend(attachments)\n",
    "    if resources:\n",
    "        state[\"resources\"].extend(resources)\n",
    "\n",
    "    return state\n",
    "\n",
    "def update_context(state: ExecutionState) -> ExecutionState:\n",
    "    asked = state[\"task\"].plan[state[\"step\"]]\n",
    "    found = state['answers']\n",
    "    context_delta = \"\\n\" + str(\n",
    "        {\n",
    "            \"asked\": asked,\n",
    "            \"found\": found,\n",
    "        }\n",
    "    ) \n",
    "    state[\"context\"] += context_delta\n",
    "\n",
    "    # TODO: IMPORTANT need to save them somewhere else? \n",
    "    state[\"resources\"] = list()\n",
    "    return state\n",
    "\n",
    "FILE_NAME_SAVED_STATE = \"state.pkl\"\n",
    "def save_state(state: ExecutionState):\n",
    "    import pickle\n",
    "    \n",
    "    with open(FILE_NAME_SAVED_STATE, \"wb\") as f:\n",
    "        pickle.dump(state, f)\n",
    "\n",
    "def load_state(path: str = FILE_NAME_SAVED_STATE) -> ExecutionState:\n",
    "    import pickle\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "workflow.add_node(\"set_task\", set_task)\n",
    "workflow.add_node(\"set_plan_step\", set_plan_step)\n",
    "workflow.add_node(\"set_capability_plan\", set_capability_plan)\n",
    "workflow.add_node(\"run_capability\", run_capability)\n",
    "workflow.add_node(\"set_capability_step\", set_capability_step)\n",
    "workflow.add_node(\"update_context\", update_context)\n",
    "\n",
    "workflow.add_edge(START, \"set_task\")\n",
    "workflow.add_edge(\"set_task\", \"set_plan_step\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"set_plan_step\",\n",
    "    check_plan_completion,\n",
    "    {\n",
    "        \"proceed\": \"set_capability_plan\",\n",
    "        \"stop\": END,\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"set_capability_plan\", \"run_capability\")\n",
    "workflow.add_edge(\"run_capability\", \"set_capability_step\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"set_capability_step\", \n",
    "    check_capability_step,\n",
    "    {\n",
    "        \"iterate\":\"run_capability\",\n",
    "        \"stop\": \"update_context\",\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"update_context\", \"set_plan_step\")\n",
    "\n",
    "generalist_graph = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(generalist_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe976b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test part nodes & logging\n",
    "import logging\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from generalist.models.core import MLFlowLLMWrapper\n",
    "from generalist.utils import pprint\n",
    "from generalist.tools import planning, web_search, text_processing\n",
    "\n",
    "# STARTING TO LOG EVERYTHING (MANUALLY ADDED)\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.set_experiment(\"test_generalist\")\n",
    "# MONKEY PATCH the llm call\n",
    "planning.llm = MLFlowLLMWrapper(planning.llm) \n",
    "web_search.llm = MLFlowLLMWrapper(web_search.llm)\n",
    "text_processing.llm = MLFlowLLMWrapper(text_processing.llm)\n",
    "\n",
    "# FIXME: delete if if wanting to test at this stage\n",
    "if False: \n",
    "        \n",
    "    question = \"Who did the actor who played Ray in the Polish-language version of Everybody Loves Raymond play in Magda M.\"\n",
    "    initial_state = init_state(question)\n",
    "\n",
    "    state = set_task(initial_state)\n",
    "    pprint(state[\"task\"].__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# web_search.web_search(state[\"task\"].question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise InterruptedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a60db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1\n",
    "import logging\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# MLFlow good at logging the state of the index and basic calls to LLM\n",
    "mlflow.langchain.autolog()\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.set_experiment(\"test_generalist\")\n",
    "mlflow.models.set_model(generalist_graph)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "question = \"Who did the actor who played Ray in the Polish-language version of Everybody Loves Raymond play in Magda M.\"\n",
    "\n",
    "initial_state = init_state(question)\n",
    "final_state = generalist_graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 \n",
    "import logging\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# MLFlow good at logging the state of the index and basic calls to LLM\n",
    "mlflow.langchain.autolog()\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.set_experiment(\"test_generalist\")\n",
    "mlflow.models.set_model(generalist_graph)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "question = \"How many at bats did the Yankee with the most walks in the 1977 regular season have that same season?\"\n",
    "\n",
    "initial_state = init_state(question)\n",
    "final_state = generalist_graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926016b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
